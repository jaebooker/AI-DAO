# AI-DAO
I propose to create a Decentralized Autonomous Organization for the purpose of incentivizing high quality AI Safety Research. Anyone on the network can propose a challenge on the DAO. This challenge can be for someone to complete any kind of research goal involving AI Alignment. The priority of challenges will be ranked based on how many tokens the proposer has staked in the network. Others in the network can then “vote up” certain proposals, which will add to the reward amount for the challenge. Anyone can then submit their own solution to the challenge. Whoever fulfills the requirements of the challenge first will receive the reward. The validity of submissions will be determined by the network, based on Proof of Stake voting. The higher stake you have in the network, the more votes you will have. The reward will then be distributed to the winner’s address.

There are possible future iterations for this, with more features. And there is also the possibility of changing some aspects if it is found they are not optimal. One possible addition is for people, with the research they want to do is not compatible with any current Challenges,  to submit their own AI Research. Independent research submissions could then be voted on by the network, with the highest voted submissions receiving the highest number of tokens. Another option is to have a button integrated with Web3, that could allow people in the network to send individual tips to researchers or research articles they find to be useful.

This project has some similarities to Kaggle. Kaggle is a centralized service with the goal of improving data science and machine learning, by allowing people to post challenges. Individuals then submit solutions, and the winner receives the reward bounty. Kaggle, however, is not a decentralized community, it is not focused on research like AI Safety, and it only allows individuals or organizations to supply the funds for their own challenges. There might be many cases where someone will want to contribute to improving AI Safety, without knowing which topics deserve the most attention. By offloading the effort of figuring out which research is most needed, people are able to rely on a decentralized community to determine what is highest priority. And individual researchers are able to work independently, without having to be formally employed with any AI organization, while also getting compensation for their work.

I believe that building this project is very feasible, and that it has a place in the ecosystem. Many in EA are already software engineers, and many are familiar with crypto projects. For this reason, initial onboarding will likely not be as difficult. Once the core team and community is formed, the goal will be to make it as user-friendly as possible, so that it will be easy for many in the AI Alignment Community to contribute and get involved.
